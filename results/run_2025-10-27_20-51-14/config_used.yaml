batch_size: 8
model: moe
moe_layer_index: 1
n_experts: 8
seq_len: 128
tokenizer: bert-base-uncased
