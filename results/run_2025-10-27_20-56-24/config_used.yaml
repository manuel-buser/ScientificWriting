batch_size: 8
d_ff: 3072
d_model: 768
model: dense
n_heads: 12
n_layers: 8
seq_len: 128
tokenizer: bert-base-uncased
